<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title> هفته هفتم on Machine Learning Andrew Ng</title>
    <link>https://mehrdad-dev.github.io/ml-andrew-ng/week7/</link>
    <description>Recent content in  هفته هفتم on Machine Learning Andrew Ng</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 12 Oct 2020 14:35:04 +0330</lastBuildDate>
    
	<atom:link href="https://mehrdad-dev.github.io/ml-andrew-ng/week7/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>بهینه سازی هدفمند</title>
      <link>https://mehrdad-dev.github.io/ml-andrew-ng/week7/optimization-objective/</link>
      <pubDate>Mon, 12 Oct 2020 14:37:24 +0330</pubDate>
      
      <guid>https://mehrdad-dev.github.io/ml-andrew-ng/week7/optimization-objective/</guid>
      <description>ماشین بردار پشتیبان (SVM) یکی دیگر از الگوریتم های یادگیری ماشین با نظارت است که گاهی تمیزتر و قدرتمندتر عمل می کند. اگر به خاطر بیاورید، ما در رگریسیون لجستیک از ضوابط زیر استفاده می کردیم:
$$ if\hspace{0.3cm} y=1,\hspace{0.2cm} then \hspace{0.3cm} h_\theta(x)\approx 1 \hspace{0.3cm} and \hspace{0.3cm}\theta\ ^ T x \gg 0 $$
$$ if\hspace{0.3cm} y=0,\hspace{0.2cm} then \hspace{0.3cm} h_\theta(x)\approx 0 \hspace{0.3cm} and \hspace{0.3cm}\theta\ ^ T x \ll 0 $$
تابع هزینه را برای رگریسیون لجستیک (نامنظم) به خاطر بیاورید:</description>
    </item>
    
    <item>
      <title>درک حاشیه اطمینان زیاد</title>
      <link>https://mehrdad-dev.github.io/ml-andrew-ng/week7/large-margin-intuition/</link>
      <pubDate>Thu, 22 Oct 2020 16:30:25 +0330</pubDate>
      
      <guid>https://mehrdad-dev.github.io/ml-andrew-ng/week7/large-margin-intuition/</guid>
      <description>یک راه مفید برای فکر کردن راجع به ماشین های بردار پشتیبان این است که آن ها را به عنوان طبقه بندی کننده هایی که حاشیه اطمینان زیادی دارند در نظر بگیرید.
$$ if \hspace{0.3cm} y=1,\hspace{0.1cm} we\hspace{0.2cm} want \hspace{0.3cm} \theta\ ^ T x \ge 1 \hspace{0.3cm}(not\hspace{0.1cm} just\hspace{0.1cm} \ge 0 ) $$
$$ if \hspace{0.3cm} y=0,\hspace{0.1cm} we\hspace{0.2cm} want \hspace{0.3cm} \theta\ ^ T x \le -1 \hspace{0.3cm}(not\hspace{0.1cm} just\hspace{0.1cm} &amp;lt; 0 ) $$</description>
    </item>
    
  </channel>
</rss>