<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title> هفته هشتم on Machine Learning Andrew Ng</title>
    <link>https://mehrdad-dev.github.io/ml-andrew-ng/week8/</link>
    <description>Recent content in  هفته هشتم on Machine Learning Andrew Ng</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 19 Oct 2020 12:16:41 +0330</lastBuildDate>
    
	<atom:link href="https://mehrdad-dev.github.io/ml-andrew-ng/week8/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>مقدمه یادگیری بدون نظارت</title>
      <link>https://mehrdad-dev.github.io/ml-andrew-ng/week8/unsupervised-learning-introduction/</link>
      <pubDate>Mon, 19 Oct 2020 12:22:06 +0330</pubDate>
      
      <guid>https://mehrdad-dev.github.io/ml-andrew-ng/week8/unsupervised-learning-introduction/</guid>
      <description>یادگیری بدون نظارت در تضاد با یادگیری با نظارت است، زیرا از یک مجموعه آموزشی بدون لیبل استفاده می‌کند.
به عبارت دیگر، ما بردار $y$ را به عنوان نتایج مورد انتظار نداریم، فقط مجموعه داده ای از ویژگی ها داریم که می‌خواهیم ساختاری در آن ها پیدا کنیم.
طبقه بندی برای موراد زیر خوب است:
 تقسیم بندی بازار تحلیل شبکه های اجتماعی سازماندهی خوشه های رایانه ای تجزیه و تحلیل داده های نجومی  </description>
    </item>
    
    <item>
      <title>الگوریتم K-Means</title>
      <link>https://mehrdad-dev.github.io/ml-andrew-ng/week8/k-means/</link>
      <pubDate>Mon, 19 Oct 2020 12:43:35 +0330</pubDate>
      
      <guid>https://mehrdad-dev.github.io/ml-andrew-ng/week8/k-means/</guid>
      <description>الگوریتم K-Means محبوب ترین و پرکاربردترین الگوریتم برای گروه بندی خودکار داده ها در زیر مجموعه های منسجم (اعضای آن به هم مربوط هستند) است.
 به طور تصادفی دو نقطه از مجموعه داده ها را به نام مرکز خوشه ای مقدار دهی می‌کنیم تخصیص خوشه: همه مثالها را به یکی از دو گروه تقسیم کنید بر اساس اینکه به کدام مرکز خوشه نزدیک است میانگین تمام نقاط داخل هر دو گروه مرکز خوشه ای را محاسبه کنید، سپس نقاط مرکز خوشه را به آن میانگین ها منتقل کنید مرحله ۲ و ۳ را دوباره اجرا کنید تا زمانی که خوشه های خود را پیدا کنید  متغیرهای اصلی ما عبارتند از:</description>
    </item>
    
    <item>
      <title>بهینه سازی هدفمند</title>
      <link>https://mehrdad-dev.github.io/ml-andrew-ng/week8/optimization-objective/</link>
      <pubDate>Thu, 22 Oct 2020 17:08:35 +0330</pubDate>
      
      <guid>https://mehrdad-dev.github.io/ml-andrew-ng/week8/optimization-objective/</guid>
      <description>برخی از پارامتر هایی را که در الگوریتم خود استفاده کردیم به یاد بیاورید:
 $ = c ^ {(i)}$ ایندکس خوشه ای ${1,2,&amp;hellip;,k}$ که به نمونه $x^{(i)}$ منتسب شده است. $ = \mu _k $ خوشه مرکزی k $(\mu _k \in \mathbb{R} ^ n)$ $ = \mu _ {c ^ {(i)}} $ مرکز خوشه ای که به نمونه $x^{(i)}$ منتسب شد است.  با استفاده از این متغیرها می‌توانیم تابع هزینه خود را تعریف کنیم:</description>
    </item>
    
    <item>
      <title>مقداردهی اولیه تصادفی</title>
      <link>https://mehrdad-dev.github.io/ml-andrew-ng/week8/random-initialization/</link>
      <pubDate>Sat, 24 Oct 2020 12:35:28 +0330</pubDate>
      
      <guid>https://mehrdad-dev.github.io/ml-andrew-ng/week8/random-initialization/</guid>
      <description>یک روش پیشنهادی برای مقداردهی اولیه تصادفی برای مرکز های خوشه ای وجود دارد.
  اگر داشته باشید $k &amp;lt; m$، یعنی اطمینان حاصل کنید که تعداد خوشه های شما از تعداد نمونه های آموزشی شما کمتر است.
  به طور تصادفی نمونه های آموزشی $k$ را انتخاب کنید.(مطمعن شوید که نمونه ها منحصر به فرد باشند)
  $\mu_1, &amp;hellip;, \mu _k$ ها را برابر با نمونه های $k$ قرار بدهید.</description>
    </item>
    
    <item>
      <title>انتخاب تعداد خوشه ها</title>
      <link>https://mehrdad-dev.github.io/ml-andrew-ng/week8/choosing-the-number-of-clusters/</link>
      <pubDate>Sat, 24 Oct 2020 13:13:58 +0330</pubDate>
      
      <guid>https://mehrdad-dev.github.io/ml-andrew-ng/week8/choosing-the-number-of-clusters/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>