<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title> هفته ششم on Machine Learning Andrew Ng</title>
    <link>https://mehrdad-dev.github.io/ml-andrew-ng/week6/</link>
    <description>Recent content in  هفته ششم on Machine Learning Andrew Ng</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 04 Oct 2020 13:22:07 +0330</lastBuildDate>
    
	<atom:link href="https://mehrdad-dev.github.io/ml-andrew-ng/week6/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>ارزیابی فرضیه</title>
      <link>https://mehrdad-dev.github.io/ml-andrew-ng/week6/evaluating-hypothesis/</link>
      <pubDate>Sun, 04 Oct 2020 13:22:30 +0330</pubDate>
      
      <guid>https://mehrdad-dev.github.io/ml-andrew-ng/week6/evaluating-hypothesis/</guid>
      <description>خطاهای موجود در پیش بینی هایتان را با استفاده از روش های زیر می‌توانید عیب یابی کنید:
 جمع آوری داده های آموزشی بیشتر استفاده از مجموعه های ویژگی کوچکتر امتحان کردن ویژگی های اضافی استفاده از ویژگی های چند جمله ای افزایش یا کاهش مقدار $\lambda$  برای عیب یابی یکی از راه های ذکر شده در بالا را به صورت تصادفی انتخاب نکنید، در بخش های بعدی تکنیک هایی برای انتخاب یکی از راه حل ها را بررسی می‌کنیم.</description>
    </item>
    
    <item>
      <title>انتخاب مدل</title>
      <link>https://mehrdad-dev.github.io/ml-andrew-ng/week6/model-selection/</link>
      <pubDate>Thu, 15 Oct 2020 17:25:10 +0330</pubDate>
      
      <guid>https://mehrdad-dev.github.io/ml-andrew-ng/week6/model-selection/</guid>
      <description>فقط به این دلیل که یک الگوریتم یادگیری متناسب با مجموعه آموزشی ما است، به این معنی نیست که آن فرضیه خوبی است!
می‌تواند overfit شده باشد، که در نتیجه پیش بینی های شما برای مجموعه آزمون ضعیف خواهد بود.
اگر خطای فرضیه خود را با داده هایی که با آن پارامتر ها را آموزش داده اید محاسبه کنید، کمتر از مجموعه داده های دیگر خواهد بود!
برای انتخاب مدل خود، می‌توانید هر درجه از چند جمله ای ها را آزمایش کرده و به نتیجه خطای آن توجه کنید.</description>
    </item>
    
    <item>
      <title>تشخیص بایاس در مقابل واریانس</title>
      <link>https://mehrdad-dev.github.io/ml-andrew-ng/week6/diagnosing-bias-variance/</link>
      <pubDate>Fri, 16 Oct 2020 19:43:49 +0000</pubDate>
      
      <guid>https://mehrdad-dev.github.io/ml-andrew-ng/week6/diagnosing-bias-variance/</guid>
      <description>در این بخش به بررسی رابطه بین درجه چند جمله ای (d) و underfit و یا overfit بودن فرضیه می‌پردازیم.
 در ابتدا لازم است که تشخیص دهیم، عاملی که باعث پیش بینی نادرست شده بایاس است یا واریانس؟ بایاس زیاد همان underfitting و واریانس زیاد همان overfitting است که باید یک میانگین مناسب بین این دو مقدار انتخاب شود.  مادامی که ما درجه چندجمله ای را افزایش می‌دهیم، خطای آموزش کاهش می‌یابد.</description>
    </item>
    
    <item>
      <title>منظم سازی و بایاس/واریانس</title>
      <link>https://mehrdad-dev.github.io/ml-andrew-ng/week6/regularization-and-bias-variance/</link>
      <pubDate>Fri, 16 Oct 2020 19:43:49 +0000</pubDate>
      
      <guid>https://mehrdad-dev.github.io/ml-andrew-ng/week6/regularization-and-bias-variance/</guid>
      <description>در ادامه به جای بررسی d و تاثیر آن بر بایاس/واریانس، نگاهی به پارامتر مرتب سازی $\lambda$ خواهیم داشت.
 $\lambda$ بزرگ: بایاس زیاد (underfitting) $\lambda$ متوسط: مقدار مناسب $\lambda$ کوچک: واریانس زیاد (overfitting)  $\lambda$ بزرگ به شدت در تمامی پارامترهای $\theta$ ایجاد نقص می‌کند که این مسئله خط تابع حاصل شده را بسیار ساده کرده و موجب underfitting خواهد شد.
رابطه $\lambda$ با مجموعه آموزشی و مجموعه واریانس به صورت زیر است:</description>
    </item>
    
    <item>
      <title>منحنی های یادگیری</title>
      <link>https://mehrdad-dev.github.io/ml-andrew-ng/week6/learning-curves/</link>
      <pubDate>Fri, 16 Oct 2020 19:43:49 +0000</pubDate>
      
      <guid>https://mehrdad-dev.github.io/ml-andrew-ng/week6/learning-curves/</guid>
      <description>آموزش 3 نمونه به آسانی خطایی برابر با صفر خواهد داشت زیرا امکان پیدا کردن یک منحنی درجه دو که دقیقا با این سه نقطه برخورد کند همیشه وجود دارد!
  هرچه مجموعه آموزشی بزرگتر می‌شود، خطای تابع درجه دو افزایش می‌یابد.
  مقدار خطا پس از تعیین اندازه m یا مجموعه آموزشی، ثابت خواهد بود.
  با بایاس زیاد مجموعه آموزشی کوچک: باعث می‌شود تا $J_{train}\left ( \Theta \right )$ کم و $J_{cv}\left ( \Theta \right )$ زیاد باشد.</description>
    </item>
    
    <item>
      <title>تصمیم گیری درباره اقدامات بعدی</title>
      <link>https://mehrdad-dev.github.io/ml-andrew-ng/week6/deciding-what-to-do-next/</link>
      <pubDate>Sat, 17 Oct 2020 20:45:00 +0330</pubDate>
      
      <guid>https://mehrdad-dev.github.io/ml-andrew-ng/week6/deciding-what-to-do-next/</guid>
      <description>روند تصمیم‌گیری ما می‌تواند به به شرح زیر باشد:
 جمع‌آوری نمونه آموزشی بیشتر: اصلاح واریانس زیاد استفاده از مجموعه کوچکتری از ویژگی‌ها: اصلاح واریانس زیاد اضافه کردن ویژگی: اصلاح بایاس زیاد اضافه کردن ویژگی‌های چندجمله‌ای: اصلاح بایاس زیاد کاهش $\lambda$: اصلاح بایاس زیاد افزایش $\lambda$: اصلاح واریانس زیاد  تشخیص شبکه‌های عصبی   یک شبکه عصبی با تعداد پارامترهای کم مستعد underfitting خواهد بود. همچنین این شبکه عصبی از نظر محاسباتی ارزان است.</description>
    </item>
    
  </channel>
</rss>